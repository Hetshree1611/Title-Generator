{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Title Generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2ZXsGfZq7VC",
        "outputId": "dd96ea15-a2ec-4473-f87f-6cf54172b2e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wltNkeuGrxN-"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils as ku\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(2)\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "\n",
        "#load all the datasets \n",
        "df1 = pd.read_csv('/content/drive/MyDrive/data/USvideos.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/data/CAvideos.csv')\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/data/GBvideos.csv')\n",
        "\n",
        "#load the datasets containing the category names\n",
        "data1 = json.load(open('/content/drive/MyDrive/data/US_category_id.json'))\n",
        "data2 = json.load(open('/content/drive/MyDrive/data/CA_category_id.json'))\n",
        "data3 = json.load(open('/content/drive/MyDrive/data/GB_category_id.json'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dknzIP_LsOCF"
      },
      "source": [
        "def category_extractor(data):\n",
        "    i_d = [data['items'][i]['id'] for i in range(len(data['items']))]\n",
        "    title = [data['items'][i]['snippet'][\"title\"] for i in range(len(data['items']))]\n",
        "    i_d = list(map(int, i_d))\n",
        "    category = zip(i_d, title)\n",
        "    category = dict(category)\n",
        "    return category\n",
        "\n",
        "#create a new category column by mapping the category names to their id\n",
        "df1['category_title'] = df1['category_id'].map(category_extractor(data1))\n",
        "df2['category_title'] = df2['category_id'].map(category_extractor(data2))\n",
        "df3['category_title'] = df3['category_id'].map(category_extractor(data3))\n",
        "\n",
        "#join the dataframes\n",
        "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
        "\n",
        "#drop rows based on duplicate videos\n",
        "df = df.drop_duplicates('video_id')\n",
        "\n",
        "#collect only titles of entertainment videos\n",
        "#feel free to use any category of video that you want\n",
        "entertainment = df[df['category_title'] == 'Entertainment']['title']\n",
        "entertainment = entertainment.tolist()\n",
        "\n",
        "\n",
        "\n",
        "#remove punctuations and convert text to lowercase\n",
        "def clean_text(text):\n",
        "    text = ''.join(e for e in text if e not in string.punctuation).lower()\n",
        "    \n",
        "    text = text.encode('utf8').decode('ascii', 'ignore')\n",
        "    return text\n",
        "\n",
        "corpus = [clean_text(e) for e in entertainment]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NVSHNO3sQUG"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    \n",
        "    ## convert data to sequence of tokens \n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences, total_words\n",
        "\n",
        "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdv8N5zysxHs",
        "outputId": "f5733e5d-28e9-4b2f-9267-e488f2e2b3f7"
      },
      "source": [
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = ku.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len\n",
        "\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n",
        "print(max_sequence_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl617AoGtboN",
        "outputId": "ecc65830-04f2-4aa2-8917-98721b17772f"
      },
      "source": [
        "def create_model(max_sequence_len, total_words):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Add Input Embedding Layer\n",
        "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "    \n",
        "    # Add Hidden Layer 1 - LSTM Layer\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.1))\n",
        "    \n",
        "    # Add Output Layer\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    \n",
        "    return model\n",
        "\n",
        "lstm_model = create_model(max_sequence_len, total_words)\n",
        "lstm_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 26, 10)            139150    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               44400     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13915)             1405415   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,588,965\n",
            "Trainable params: 1,588,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV6Dr2GvyS08",
        "outputId": "d588cb2f-f1e7-4274-e342-995285019bd0"
      },
      "source": [
        "lstm_model.fit(predictors, label, epochs=5, verbose=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Epoch 2/5\n",
            "Epoch 3/5\n",
            "Epoch 4/5\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7755bf0d50>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw3TSWuDtram"
      },
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        #predicted = model.predict_classes(token_list, verbose=0)\n",
        "        predicted = np.argmax(model.predict(token_list,verbose=0), axis=-1)\n",
        "        \n",
        "        output_word = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "    return seed_text.title()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tc6BB1-t7OV",
        "outputId": "1f4408da-71a7-4e6e-c4d0-345f6b720544"
      },
      "source": [
        "print (generate_text(\"\", 5, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"euclidean\", 4, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"generative\", 5, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"ground breaking\", 5, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"new\", 4, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"understanding\", 5, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"long short term memory\", 6, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"LSTM\", 6, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"a\", 5, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"anomaly\", 5, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"data\", 7, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"designing\", 7, lstm_model, max_sequence_len))\n",
        "print (generate_text(\"reinforcement\", 7, lstm_model, max_sequence_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " React To Try To The\n",
            "Euclidean React To Try To\n",
            "Generative React To Try To The\n",
            "Ground Breaking The Thinks The Webs On\n",
            "New Panther Of The Last\n",
            "Understanding React To Try To The\n",
            "Long Short Term Memory On The Last Jedi The Hd\n",
            "Lstm React To Try To The Last\n",
            "A Voice 2018 Blind Hd Or\n",
            "Anomaly React To Try To The\n",
            "Data Voice Episode 1 Hum Tv Episode 12\n",
            "Designing React To Try To The Last Jedi\n",
            "Reinforcement React To Try To The Last Jedi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJuTFhP_2Auj",
        "outputId": "575a5283-147e-4c79-eb2e-cd9ecb0e3d2e"
      },
      "source": [
        "print (generate_text(\"Spiderman\", 7, lstm_model, max_sequence_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spiderman The Last Jedi The Hd Of The\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5qrBRJ92GED",
        "outputId": "8261f248-355a-448d-829d-cb5703bb7ae7"
      },
      "source": [
        "print (generate_text(\"HUM\", 7, lstm_model, max_sequence_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hum Episode 23 7Th May 2018 Ary Digital\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1kKPRUtApHb",
        "outputId": "ff31291e-ea90-4274-fd5f-cf6952bd2961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print (generate_text(\"Shaktiman\", 7, lstm_model, max_sequence_len))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shaktiman React To Try To The Last Jedi\n"
          ]
        }
      ]
    }
  ]
}